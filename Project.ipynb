{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for training `QDA` :\n",
    "- takes the inputs : $X_{app}$ (training input matrix $n, p$), $z_{app}$ (binary class indicator matrix $n, K$), $m_{prior}$ (Gaussian prior expectation matrix $K, p$), $df_{exp}$ (Gaussian prior shrinkage parameter), $S_{prior}$ (covariance matrix $p, p, K$ for the inverse -Wishart prior), $df_{cov}$ (degree of freedom of the inverse-Wishart prior)\n",
    "- provides : $pi$ (vector $K, 1$ of class proportions), $mu$ (estimated expectation matrix $K, p$), $Sig$ (estimated covariance matrices $p, p, K$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QDA(Xapp, zapp, mprior, df_exp, Sprior, df_cov):\n",
    "    n, p, K =  Xapp.shape[0], Xapp.shape[1], zapp.shape[1]\n",
    "    pi = np.zeros(K)\n",
    "    mu = np.zeros((K, p))\n",
    "    B = np.zeros((p, p, n))\n",
    "    Sig = np.zeros((p, p, K))\n",
    "    \n",
    "    pi = np.mean(zapp, axis=0)\n",
    "    for j in range(K):\n",
    "        mu[j, :] = (sum(zapp[i, j] * Xapp[i, :] for i in range(n)) \n",
    "                    + df_exp * mprior[j, :]) / (sum(zapp[:, j]) + df_exp)\n",
    "        \n",
    "        for i in range(n):\n",
    "            temp = (Xapp[i, :] - mprior[j, :]).reshape((p, -1))\n",
    "            B[:, :, i] = temp @ temp.T\n",
    "        \n",
    "        Sig[:, :, j] = (sum((zapp[i, j] * B[:, :, i]) for i in range(n)) + \n",
    "                        df_exp * (mu[j, :] - mprior[j, :]) @ (mu[j, :] - mprior[j, :]).T + \n",
    "                        Sprior[:, :, j]) / (sum(zapp[:, j]) + df_cov + p + 2)\n",
    "        \n",
    "    return pi, mu, Sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QDA_without_prior(Xapp, zapp):\n",
    "    n, p, K =  Xapp.shape[0], Xapp.shape[1], zapp.shape[1]\n",
    "    pi = np.zeros(K)\n",
    "    mu = np.zeros((K, p))\n",
    "    B = np.zeros((p, p, n))\n",
    "    Sig = np.zeros((p, p, K))\n",
    "    \n",
    "    pi = np.mean(zapp, axis=0)\n",
    "    for j in range(K):\n",
    "        mu[j, :] = sum(zapp[i, j] * Xapp[i, :] for i in range(n))\n",
    "        \n",
    "        for i in range(n):\n",
    "            temp = (Xapp[i, :] - mu[j, :]).reshape((p, -1))\n",
    "            B[:, :, i] = temp @ temp.T\n",
    "        \n",
    "        Sig[:, :, j] = sum((zapp[i, j] * B[:, :, i]) for i in range(n))\n",
    "        \n",
    "    return pi, mu, Sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for evaluating test set `evaluation` :\n",
    "- takes the inputs : $X_{tst}$ (test input matrix $n, p$), $pi$ (vector $K, 1$ of class proportions), $mu$ (estimated expectation matrix $K, p$), $Sig$ (estimated covariance matrices $p, p, K$)\n",
    "- provides : $prob$ (matrix $n, K$ of estimated class posterior probabilities) and $pred$ (vector $n, 1$ of corresponding decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(Xtst, pi, mu, Sig):\n",
    "    n, p, K = Xtst.shape[0], Xtst.shape[1], len(pi)\n",
    "    prob = np.zeros((n, K))\n",
    "    pred = np.zeros(n)\n",
    "    \n",
    "    f = lambda x, mu, Sig: (2 * np.pi)**(-n/2) * np.linalg.det(Sig)**(-1/2) * np.exp((-1/2) * \n",
    "                                                                                     (x - mu).T\n",
    "                                                                                     @ np.linalg.inv(Sig)\n",
    "                                                                                     @ (x - mu))\n",
    "   \n",
    "    for j in range(K):\n",
    "        for i in range(n):\n",
    "            total = sum(pi[k] * f(Xtst[i, :], mu[k, :], Sig[:, :, k]) for k in range(K))\n",
    "            prob[i, j] = pi[j] * f(Xtst[i, :], mu[j, :], Sig[:, :, j]) / total\n",
    "        \n",
    "    pred = np.argmax(prob, axis=1)\n",
    "    \n",
    "    return prob, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `data_processing` function to test different dataset. The function does respectively :\n",
    "- Read the dataset by the `pandas` library and transform it to the one in form of the `numpy` library in order to facilitate our next works.\n",
    "- Apply PCA filtering process to the dataset if necessary.\n",
    "- Sort all classes of the dataset and display their enumeration\n",
    "- Separate the dataset into training and test ones by `cut_off` coefficient predefined at `0.9`\n",
    "- Calculate the prior expectation and variance based on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(file_url, n_components_pca=None, cut_off=0.9):\n",
    "    data = pd.read_csv(file_url, header=0)\n",
    "    data = data.to_numpy()\n",
    "    \n",
    "    if n_components_pca is not None:\n",
    "        data_y = data[:, -1]\n",
    "        data_X = data[:, :-1]\n",
    "        pca = PCA(n_components=n_components_pca)\n",
    "        data_X = pca.fit_transform(data_X)\n",
    "        data = np.hstack((data_X, data_y.reshape((-1,1))))\n",
    "    \n",
    "    classes = sorted(collections.Counter(list(data[:, -1])).keys())\n",
    "    classes_with_index = {}\n",
    "    \n",
    "    K = len(classes)\n",
    "    n, p = data.shape[0], data.shape[1] - 1\n",
    "    for i_class in range(K):\n",
    "        classes_with_index[i_class] = classes[i_class]\n",
    "        data[data[:, -1] == classes[i_class], -1] = i_class\n",
    "    print(\"Ours classes are enumerated as bellow : \\n\", classes_with_index)\n",
    "    \n",
    "    cut_off = int(cut_off*data.shape[0])\n",
    "    if cut_off > data.shape[0]:\n",
    "        raise IndexError(\"list index out of range\")\n",
    "    else:\n",
    "        Xapp = data[0:cut_off, :-1]\n",
    "        Xtst = data[cut_off:, :-1]\n",
    "\n",
    "        Zapp = np.zeros((cut_off, K))\n",
    "        Ztst = np.zeros((n - cut_off, K))\n",
    "\n",
    "        for i in range(cut_off):\n",
    "            Zapp[i, int(data[i, -1])] = 1\n",
    "        for i in range(cut_off, n):\n",
    "            Ztst[i - cut_off, int(data[i, -1])] = 1\n",
    "    \n",
    "    mprior = np.zeros((K, p))\n",
    "    Sprior = np.zeros((p, p, K))\n",
    "    for j in range(K):\n",
    "        temp = data[data[:, -1] == j, :-1]\n",
    "        temp = temp.astype(float)\n",
    "        mprior[j, :] = temp.mean(axis = 0)\n",
    "        Sprior[:, :, j] = np.cov(temp, rowvar=False)\n",
    "    return Xapp, Zapp, Xtst, Ztst, mprior, Sprior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `optdigits` dataset has many zero elements that make itselft correlated. That's why the result from the inital training datatset is badly evaluated. We then apply a PCA filtering process with number of principal components depending on the `cut_off` coefficient (rank of training set) in order to eliminate the correlated ones. As a result, we get much better performance. <br>\n",
    "For the choice of the shrinkage parameter $df_{exp}$ and the degree of freedom $df_{co}v$, we a priori choose $df_{exp} = 10$ and $df_{cov} = 300$ for this dataset and also the next ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 0.0, 1: 1.0, 2: 2.0, 3: 3.0, 4: 4.0, 5: 5.0, 6: 6.0, 7: 7.0, 8: 8.0, 9: 9.0}\n",
      "\n",
      "\n",
      " [[54  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 53  0  0  0  0  0  0  0  5]\n",
      " [ 0  0 54  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  2  0  2  3  0]\n",
      " [ 0  0  0  0 57  0  0  1  1  0]\n",
      " [ 0  0  0  0  0 55  0  0  1  0]\n",
      " [ 0  0  0  0  0  0 56  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 57  0  0]\n",
      " [ 0  4  0  1  0  0  0  1 41  6]\n",
      " [ 0  0  0  1  0  2  0  0  0 53]]\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        55\n",
      "           1       0.93      0.91      0.92        58\n",
      "           2       1.00      1.00      1.00        54\n",
      "           3       0.96      0.88      0.92        57\n",
      "           4       0.98      0.97      0.97        59\n",
      "           5       0.93      0.98      0.96        56\n",
      "           6       1.00      0.98      0.99        57\n",
      "           7       0.93      1.00      0.97        57\n",
      "           8       0.87      0.77      0.82        53\n",
      "           9       0.83      0.95      0.88        56\n",
      "\n",
      "    accuracy                           0.94       562\n",
      "   macro avg       0.94      0.94      0.94       562\n",
      "weighted avg       0.94      0.94      0.94       562\n",
      "\n",
      "\n",
      "\n",
      " 0.9444750942267841\n"
     ]
    }
   ],
   "source": [
    "df_exp_opt = 10\n",
    "df_cov_opt = 300\n",
    "#cuts_off = np.array([0.9, 0.91, 0.92, 0.93, 0.94, 0.95])\n",
    "#prediction = np.zeros(4)\n",
    "\n",
    "#for i in range(len(cuts_off))\n",
    "Xapp_opt, Zapp_opt, Xtst_opt, Ztst_opt, mprior_opt, Sprior_opt = data_processing(\n",
    "                                            \"dataset/optdigits.csv\", n_components_pca=10, cut_off=0.9)\n",
    "pi_opt, mu_opt, Sig_opt = QDA(Xapp_opt, Zapp_opt, mprior_opt, df_exp_opt, Sprior_opt, df_cov_opt)\n",
    "prob_opt, pred_opt = evaluation(Xtst_opt, pi_opt, mu_opt, Sig_opt)\n",
    "#prediction[i] = precision_score(np.argmax(Ztst_opt, axis=1), pred_opt, average='weighted')\n",
    "\n",
    "print('\\n\\n', confusion_matrix(np.argmax(Ztst_opt, axis=1), pred_opt))\n",
    "print('\\n\\n', classification_report(np.argmax(Ztst_opt, axis=1), pred_opt))\n",
    "print('\\n\\n', precision_score(np.argmax(Ztst_opt, axis=1), pred_opt, average='weighted'))\n",
    "\n",
    "#plt.plot(cuts_off, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " [[55  0  0  0  0  0  0  0  0  0]\n",
      " [58  0  0  0  0  0  0  0  0  0]\n",
      " [54  0  0  0  0  0  0  0  0  0]\n",
      " [57  0  0  0  0  0  0  0  0  0]\n",
      " [59  0  0  0  0  0  0  0  0  0]\n",
      " [56  0  0  0  0  0  0  0  0  0]\n",
      " [57  0  0  0  0  0  0  0  0  0]\n",
      " [57  0  0  0  0  0  0  0  0  0]\n",
      " [53  0  0  0  0  0  0  0  0  0]\n",
      " [56  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      1.00      0.18        55\n",
      "           1       0.00      0.00      0.00        58\n",
      "           2       0.00      0.00      0.00        54\n",
      "           3       0.00      0.00      0.00        57\n",
      "           4       0.00      0.00      0.00        59\n",
      "           5       0.00      0.00      0.00        56\n",
      "           6       0.00      0.00      0.00        57\n",
      "           7       0.00      0.00      0.00        57\n",
      "           8       0.00      0.00      0.00        53\n",
      "           9       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.10       562\n",
      "   macro avg       0.01      0.10      0.02       562\n",
      "weighted avg       0.01      0.10      0.02       562\n",
      "\n",
      "\n",
      "\n",
      " 0.009577512949430732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huydung/miniconda3/envs/aos1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/huydung/miniconda3/envs/aos1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pi_opt_2, mu_opt_2, Sig_opt_2 = QDA_without_prior(Xapp_opt, Zapp_opt)\n",
    "prob_opt_2, pred_opt_2 = evaluation(Xtst_opt, pi_opt_2, mu_opt_2, Sig_opt_2)\n",
    "#prediction[i] = precision_score(np.argmax(Ztst_opt, axis=1), pred_opt, average='weighted')\n",
    "\n",
    "print('\\n\\n', confusion_matrix(np.argmax(Ztst_opt, axis=1), pred_opt_2))\n",
    "print('\\n\\n', classification_report(np.argmax(Ztst_opt, axis=1), pred_opt_2))\n",
    "print('\\n\\n', precision_score(np.argmax(Ztst_opt, axis=1), pred_opt_2, average='weighted'))\n",
    "\n",
    "#plt.plot(cuts_off, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 1.0, 1: 2.0, 2: 3.0, 3: 4.0, 4: 5.0}\n",
      "\n",
      "\n",
      "\n",
      "[[428   5   0   2  15]\n",
      " [ 13  59   0   0   0]\n",
      " [  2   0   2   0   0]\n",
      " [  2   0   0  15   0]\n",
      " [  2   0   0   0   3]]\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       450\n",
      "           1       0.92      0.82      0.87        72\n",
      "           2       1.00      0.50      0.67         4\n",
      "           3       0.88      0.88      0.88        17\n",
      "           4       0.17      0.60      0.26         5\n",
      "\n",
      "    accuracy                           0.93       548\n",
      "   macro avg       0.79      0.75      0.73       548\n",
      "weighted avg       0.94      0.93      0.93       548\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.9435781323992881\n"
     ]
    }
   ],
   "source": [
    "Xapp_pag, Zapp_pag, Xtst_pag, Ztst_pag, mprior_pag, Sprior_pag = data_processing(\"dataset/page-blocks.csv\")\n",
    "\n",
    "df_exp_pag = 10\n",
    "df_cov_pag = 300\n",
    "\n",
    "pi_pag, mu_pag, Sig_pag = QDA(Xapp_pag, Zapp_pag, mprior_pag, df_exp_pag, Sprior_pag, df_cov_pag)\n",
    "prob_pag, pred_pag = evaluation(Xtst_pag, pi_pag, mu_pag, Sig_pag)\n",
    "\n",
    "print('\\n\\n')\n",
    "print(confusion_matrix(np.argmax(Ztst_pag, axis=1), pred_pag))\n",
    "print('\\n\\n')\n",
    "print(classification_report(np.argmax(Ztst_pag, axis=1), pred_pag))\n",
    "print('\\n\\n')\n",
    "print(precision_score(np.argmax(Ztst_pag, axis=1), pred_pag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 1.0, 1: 2.0, 2: 3.0, 3: 4.0, 4: 5.0, 5: 7.0}\n",
      "\n",
      "\n",
      "\n",
      "[[164   0   1   0   3   0]\n",
      " [  0  63   0   0   1   0]\n",
      " [  1   2 134   1   1   1]\n",
      " [  1   3  20  12   5  28]\n",
      " [  1   2   0   0  64   2]\n",
      " [  0   3   5   6   5 114]]\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       168\n",
      "           1       0.86      0.98      0.92        64\n",
      "           2       0.84      0.96      0.89       140\n",
      "           3       0.63      0.17      0.27        69\n",
      "           4       0.81      0.93      0.86        69\n",
      "           5       0.79      0.86      0.82       133\n",
      "\n",
      "    accuracy                           0.86       643\n",
      "   macro avg       0.82      0.81      0.79       643\n",
      "weighted avg       0.84      0.86      0.83       643\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.8421588047083794\n"
     ]
    }
   ],
   "source": [
    "Xapp_sat, Zapp_sat, Xtst_sat, Ztst_sat, mprior_sat, Sprior_sat = data_processing(\"dataset/satimage.csv\")\n",
    "\n",
    "df_exp_sat = 10\n",
    "df_cov_sat = 300\n",
    "\n",
    "pi_sat, mu_sat, Sig_sat = QDA(Xapp_sat, Zapp_sat, mprior_sat, df_exp_sat, Sprior_sat, df_cov_sat)\n",
    "prob_sat, pred_sat = evaluation(Xtst_sat, pi_sat, mu_sat, Sig_sat)\n",
    "\n",
    "print('\\n\\n')\n",
    "print(confusion_matrix(np.argmax(Ztst_sat, axis=1), pred_sat))\n",
    "print('\\n\\n')\n",
    "print(classification_report(np.argmax(Ztst_sat, axis=1), pred_sat))\n",
    "print('\\n\\n')\n",
    "print(precision_score(np.argmax(Ztst_sat, axis=1), pred_sat, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 'brickface', 1: 'cement', 2: 'foliage', 3: 'grass', 4: 'path', 5: 'sky', 6: 'window'}\n",
      "\n",
      "\n",
      "\n",
      "[[25  1  0  0  0  0  2]\n",
      " [ 0 37  0  0  0  0  2]\n",
      " [ 0  0 16  0  0  0 12]\n",
      " [ 0  0  0 29  0  0  0]\n",
      " [ 0  4  0  0 31  0  0]\n",
      " [ 0  0  0  0  0 38  0]\n",
      " [ 0 11  1  0  0  0 22]]\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        28\n",
      "           1       0.70      0.95      0.80        39\n",
      "           2       0.94      0.57      0.71        28\n",
      "           3       1.00      1.00      1.00        29\n",
      "           4       1.00      0.89      0.94        35\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.58      0.65      0.61        34\n",
      "\n",
      "    accuracy                           0.86       231\n",
      "   macro avg       0.89      0.85      0.86       231\n",
      "weighted avg       0.88      0.86      0.86       231\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.879928860593619\n"
     ]
    }
   ],
   "source": [
    "Xapp_seg, Zapp_seg, Xtst_seg, Ztst_seg, mprior_seg, Sprior_seg = data_processing(\"dataset/segment.csv\",\n",
    "                                                                                n_components_pca=17)\n",
    "\n",
    "df_exp_seg = 10\n",
    "df_cov_seg = 300\n",
    "\n",
    "pi_seg, mu_seg, Sig_seg = QDA(Xapp_seg, Zapp_seg, mprior_seg, df_exp_seg, Sprior_seg, df_cov_seg)\n",
    "prob_seg, pred_seg = evaluation(Xtst_seg, pi_seg, mu_seg, Sig_seg)\n",
    "\n",
    "print('\\n\\n')\n",
    "print(confusion_matrix(np.argmax(Ztst_seg, axis=1), pred_seg))\n",
    "print('\\n\\n')\n",
    "print(classification_report(np.argmax(Ztst_seg, axis=1), pred_seg))\n",
    "print('\\n\\n')\n",
    "print(precision_score(np.argmax(Ztst_seg, axis=1), pred_seg, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9766310415063318 1;p+20 ll\n",
    "# 0.9758926103474012 10;p+20\n",
    "# 0.9671482548426473 10;p+300 \n",
    "# v reprensent the least informative -> v high -> cov lower -> more \"confident\" ????\n",
    "# high df_cov -> Sig =~~ sampling covariance matrix (in this case Sprior)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
