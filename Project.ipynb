{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions\n",
    "\n",
    "The function for training `QDA` :\n",
    "- takes the inputs : $X_{app}$ (training input matrix $n, p$), $z_{app}$ (binary class indicator matrix $n, K$), $m_{prior}$ (Gaussian prior expectation matrix $K, p$), $df_{exp}$ (Gaussian prior shrinkage parameter), $S_{prior}$ (covariance matrix $p, p, K$ for the inverse -Wishart prior), $df_{cov}$ (degree of freedom of the inverse-Wishart prior)\n",
    "- provides : $pi$ (vector $K, 1$ of class proportions), $mu$ (estimated expectation matrix $K, p$), $Sig$ (estimated covariance matrices $p, p, K$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QDA(Xapp, zapp, mprior, df_exp, Sprior, df_cov):\n",
    "    n, p, K =  Xapp.shape[0], Xapp.shape[1], zapp.shape[1]\n",
    "    pi = np.zeros(K)\n",
    "    mu = np.zeros((K, p))\n",
    "    B = np.zeros((p, p, n))\n",
    "    Sig = np.zeros((p, p, K))\n",
    "    \n",
    "    pi = np.mean(zapp, axis=0)\n",
    "    for j in range(K):\n",
    "        mu[j, :] = (sum(zapp[i, j] * Xapp[i, :] for i in range(n)) \n",
    "                    + df_exp * mprior[j, :]) / (sum(zapp[:, j]) + df_exp)\n",
    "        \n",
    "        for i in range(n):\n",
    "            temp = (Xapp[i, :] - mprior[j, :]).reshape((p, -1))\n",
    "            B[:, :, i] = temp @ temp.T\n",
    "        \n",
    "        Sig[:, :, j] = (sum((zapp[i, j] * B[:, :, i]) for i in range(n)) + \n",
    "                        df_exp * (mu[j, :] - mprior[j, :]) @ (mu[j, :] - mprior[j, :]).T + \n",
    "                        Sprior[:, :, j].T) / (sum(zapp[:, j]) + df_cov + p + 2)\n",
    "    return pi, mu, Sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QDA_without_prior(Xapp, zapp):\n",
    "    n, p, K =  Xapp.shape[0], Xapp.shape[1], zapp.shape[1]\n",
    "    pi = np.zeros(K)\n",
    "    mu = np.zeros((K, p))\n",
    "    B = np.zeros((p, p, n))\n",
    "    Sig = np.zeros((p, p, K))\n",
    "    \n",
    "    pi = np.mean(zapp, axis=0)\n",
    "    for j in range(K):\n",
    "        mu[j, :] = sum(zapp[i, j] * Xapp[i, :] for i in range(n))\n",
    "        \n",
    "        for i in range(n):\n",
    "            temp = (Xapp[i, :] - mu[j, :]).reshape((p, -1))\n",
    "            \n",
    "            B[:, :, i] = temp @ temp.T\n",
    "        \n",
    "        Sig[:, :, j] = sum((zapp[i, j] * B[:, :, i]) for i in range(n)) / sum(zapp[:, j])\n",
    "    return pi, mu, Sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for evaluating test set `evaluation` :\n",
    "- takes the inputs : $X_{tst}$ (test input matrix $n, p$), $pi$ (vector $K, 1$ of class proportions), $mu$ (estimated expectation matrix $K, p$), $Sig$ (estimated covariance matrices $p, p, K$)\n",
    "- provides : $prob$ (matrix $n, K$ of estimated class posterior probabilities) and $pred$ (vector $n, 1$ of corresponding decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(Xtst, pi, mu, Sig):\n",
    "    n, p, K = Xtst.shape[0], Xtst.shape[1], len(pi)\n",
    "    prob = np.zeros((n, K))\n",
    "    pred = np.zeros(n)\n",
    "    \n",
    "    f = lambda x, mu, Sig: np.linalg.det(Sig)**(-1/2) * np.exp((-1/2) *(x - mu).T\n",
    "                                                               @ np.linalg.inv(Sig)\n",
    "                                                               @ (x - mu))\n",
    "   \n",
    "    for j in range(K):\n",
    "        for i in range(n):\n",
    "            total = sum(pi[k] * f(Xtst[i, :], mu[k, :], Sig[:, :, k]) for k in range(K))\n",
    "            prob[i, j] = pi[j] * f(Xtst[i, :], mu[j, :], Sig[:, :, j]) / total\n",
    "        \n",
    "    pred = np.argmax(prob, axis=1)\n",
    "    \n",
    "    return prob, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `data_processing` function to test different dataset. The function does respectively :\n",
    "- Read the dataset by the `pandas` library and transform it to the one in form of the `numpy` library in order to facilitate our next works.\n",
    "- Apply PCA filtering process to the dataset if necessary.\n",
    "- Sort all classes of the dataset and display their enumeration\n",
    "- Separate the dataset into training and test ones by `cut_off` coefficient predefined at `0.9`\n",
    "- Calculate the prior expectation and variance based on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(file_url, n_components_pca=None, test_size=0.3):\n",
    "    data = pd.read_csv(file_url, header=0)\n",
    "    data = data.to_numpy()\n",
    "    \n",
    "    if n_components_pca is not None:\n",
    "        data_y = data[:, -1]\n",
    "        data_X = data[:, :-1]\n",
    "        pca = PCA(n_components=n_components_pca)\n",
    "        data_X = pca.fit_transform(data_X)\n",
    "        data = np.hstack((data_X, data_y.reshape((-1,1))))\n",
    "    \n",
    "    classes = sorted(collections.Counter(list(data[:, -1])).keys())\n",
    "    classes_with_index = {}\n",
    "    \n",
    "    K = len(classes)\n",
    "    n, p = data.shape[0], data.shape[1] - 1\n",
    "    for i_class in range(K):\n",
    "        classes_with_index[i_class] = classes[i_class]\n",
    "        data[data[:, -1] == classes[i_class], -1] = i_class\n",
    "    print(\"Ours classes are enumerated as bellow : \\n\", classes_with_index)\n",
    "    \n",
    "    if test_size > 1 or test_size < 0:\n",
    "        raise IndexError(\"invalid value of test_size\")\n",
    "    else:\n",
    "        Xapp, Xtst, yapp, ytst = train_test_split(data[:, :-1], data[:, -1], test_size=test_size)\n",
    "\n",
    "        Zapp = np.zeros((len(yapp), K))\n",
    "        Ztst = np.zeros((len(ytst), K))\n",
    "        for i in range(len(yapp)):\n",
    "            Zapp[i, int(yapp[i])] = 1\n",
    "        for i in range(len(ytst)):\n",
    "            Ztst[i, int(ytst[i])] = 1\n",
    "    \n",
    "    mprior = np.zeros((K, p))\n",
    "    Sprior = np.zeros((p, p, K))\n",
    "    for j in range(K):\n",
    "        temp = data[data[:, -1] == j, :-1]\n",
    "        temp = temp.astype(float)\n",
    "        mprior[j, :] = temp.mean(axis = 0)\n",
    "        Sprior[:, :, j] = np.cov(temp, rowvar=False)\n",
    "    return Xapp, Zapp, Xtst, Ztst, mprior, Sprior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optdigits test\n",
    "\n",
    "The `optdigits` dataset has many zero elements that make itselft correlated. That's why the result from the inital training datatset is badly evaluated. We then apply a PCA filtering process with number of principal components depending on the `cut_off` coefficient (rank of training set) in order to eliminate the correlated ones. As a result, we get much better performance. <br>\n",
    "For the choice of the shrinkage parameter $df_{exp}$ and the degree of freedom $df_{co}v$, we a priori choose $df_{exp} = 10$ and $df_{cov} = 300$ for this dataset and also the next ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 0.0, 1: 1.0, 2: 2.0, 3: 3.0, 4: 4.0, 5: 5.0, 6: 6.0, 7: 7.0, 8: 8.0, 9: 9.0}\n",
      "\n",
      "\n",
      " [[154   0   0   0   0   1   0   0   0   0]\n",
      " [  0 161   0   1   1   0   0   0   0   1]\n",
      " [  0   1 180   1   0   0   0   0   0   1]\n",
      " [  0   0   0 165   0   0   0   1   0   0]\n",
      " [  0   0   0   0 170   0   0   0   0   2]\n",
      " [  0   0   0   1   1 149   0   0   2   3]\n",
      " [  0   0   0   0   1   0 180   0   0   0]\n",
      " [  0   0   0   0   0   0   0 175   0   0]\n",
      " [  0   2   0   0   0   0   0   0 159   0]\n",
      " [  0   0   0   0   1   0   0   1   2 169]]\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       155\n",
      "           1       0.98      0.98      0.98       164\n",
      "           2       1.00      0.98      0.99       183\n",
      "           3       0.98      0.99      0.99       166\n",
      "           4       0.98      0.99      0.98       172\n",
      "           5       0.99      0.96      0.97       156\n",
      "           6       1.00      0.99      1.00       181\n",
      "           7       0.99      1.00      0.99       175\n",
      "           8       0.98      0.99      0.98       161\n",
      "           9       0.96      0.98      0.97       173\n",
      "\n",
      "    accuracy                           0.99      1686\n",
      "   macro avg       0.99      0.99      0.99      1686\n",
      "weighted avg       0.99      0.99      0.99      1686\n",
      "\n",
      "\n",
      "\n",
      " 0.9859031364790537\n"
     ]
    }
   ],
   "source": [
    "df_exp_opt = 0.1\n",
    "df_cov_opt = 65\n",
    "\n",
    "Xapp_opt, Zapp_opt, Xtst_opt, Ztst_opt, mprior_opt, Sprior_opt = data_processing(\n",
    "                                            \"dataset/optdigits.csv\", n_components_pca=20)\n",
    "pi_opt, mu_opt, Sig_opt = QDA(Xapp_opt, Zapp_opt, mprior_opt, df_exp_opt, Sprior_opt, df_cov_opt)\n",
    "prob_opt, pred_opt = evaluation(Xtst_opt, pi_opt, mu_opt, Sig_opt)\n",
    "\n",
    "print('\\n\\n', confusion_matrix(np.argmax(Ztst_opt, axis=1), pred_opt))\n",
    "print('\\n\\n', classification_report(np.argmax(Ztst_opt, axis=1), pred_opt))\n",
    "print('\\n\\n', precision_score(np.argmax(Ztst_opt, axis=1), pred_opt, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " [[154   0   0   0   0   1   0   0   0   0]\n",
      " [  0 160   0   1   1   0   0   0   1   1]\n",
      " [  0   2 178   0   0   1   0   1   0   1]\n",
      " [  0   0   0 166   0   0   0   0   0   0]\n",
      " [  0   0   0   0 169   0   0   0   0   3]\n",
      " [  0   0   0   2   0 147   0   1   2   4]\n",
      " [  0   0   0   0   0   1 179   0   0   1]\n",
      " [  0   1   0   0   0   0   0 174   0   0]\n",
      " [  0   3   0   1   0   0   0   0 157   0]\n",
      " [  0   0   0   0   1   0   0   1   2 169]]\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       155\n",
      "           1       0.96      0.98      0.97       164\n",
      "           2       1.00      0.97      0.99       183\n",
      "           3       0.98      1.00      0.99       166\n",
      "           4       0.99      0.98      0.99       172\n",
      "           5       0.98      0.94      0.96       156\n",
      "           6       1.00      0.99      0.99       181\n",
      "           7       0.98      0.99      0.99       175\n",
      "           8       0.97      0.98      0.97       161\n",
      "           9       0.94      0.98      0.96       173\n",
      "\n",
      "    accuracy                           0.98      1686\n",
      "   macro avg       0.98      0.98      0.98      1686\n",
      "weighted avg       0.98      0.98      0.98      1686\n",
      "\n",
      "\n",
      "\n",
      " 0.9806848570169601\n"
     ]
    }
   ],
   "source": [
    "pi_opt_2, mu_opt_2, Sig_opt_2 = QDA_without_prior(Xapp_opt, Zapp_opt)\n",
    "prob_opt_2, pred_opt_2 = evaluation(Xtst_opt, pi_opt_2, mu_opt_2, Sig_opt_2)\n",
    "\n",
    "print('\\n\\n', confusion_matrix(np.argmax(Ztst_opt, axis=1), pred_opt_2))\n",
    "print('\\n\\n', classification_report(np.argmax(Ztst_opt, axis=1), pred_opt_2))\n",
    "print('\\n\\n', precision_score(np.argmax(Ztst_opt, axis=1), pred_opt_2, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_exp_opt = 0.1\n",
    "df_cov_opt = 65\n",
    "cuts_off = np.array([0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "prediction = np.zeros(7)\n",
    "prediction_without_prior = np.zeros(7)\n",
    "\n",
    "for i in range(len(cuts_off)):\n",
    "    Xapp_opt, Zapp_opt, Xtst_opt, Ztst_opt, mprior_opt, Sprior_opt = data_processing(\n",
    "                                            \"dataset/optdigits.csv\", n_components_pca=10, cut_off=cuts_off[i])\n",
    "    \n",
    "    pi_opt, mu_opt, Sig_opt = QDA(Xapp_opt, Zapp_opt, mprior_opt, df_exp_opt, Sprior_opt, df_cov_opt)\n",
    "    prob_opt, pred_opt = evaluation(Xtst_opt, pi_opt, mu_opt, Sig_opt)\n",
    "    prediction[i] = precision_score(np.argmax(Ztst_opt, axis=1), pred_opt, average='weighted')\n",
    "    \n",
    "    pi_opt_2, mu_opt_2, Sig_opt_2 = QDA_without_prior(Xapp_opt, Zapp_opt)\n",
    "    prob_opt_2, pred_opt_2 = evaluation(Xtst_opt, pi_opt_2, mu_opt_2, Sig_opt_2)\n",
    "    prediction_without_prior[i] = precision_score(np.argmax(Ztst_opt, axis=1), pred_opt_2, average='weighted')\n",
    "\n",
    "plt.plot(cuts_off, prediction)\n",
    "plt.plot(cuts_off, prediction_without_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 1.0, 1: 2.0, 2: 3.0, 3: 4.0, 4: 5.0}\n",
      "\n",
      "\n",
      "\n",
      "[[424   5   0   3  18]\n",
      " [ 10  56   0   6   0]\n",
      " [  0   0   4   0   0]\n",
      " [  0   0   0  16   1]\n",
      " [  1   0   1   0   3]]\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       450\n",
      "           1       0.92      0.78      0.84        72\n",
      "           2       0.80      1.00      0.89         4\n",
      "           3       0.64      0.94      0.76        17\n",
      "           4       0.14      0.60      0.22         5\n",
      "\n",
      "    accuracy                           0.94      1642\n",
      "   macro avg       0.74      0.73      0.71      1642\n",
      "weighted avg       0.95      0.94      0.94      1642\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.9499717966943255\n"
     ]
    }
   ],
   "source": [
    "Xapp_pag, Zapp_pag, Xtst_pag, Ztst_pag, mprior_pag, Sprior_pag = data_processing(\"dataset/page-blocks.csv\")\n",
    "\n",
    "df_exp_pag = 0.1\n",
    "df_cov_pag = 65\n",
    "\n",
    "pi_pag, mu_pag, Sig_pag = QDA(Xapp_pag, Zapp_pag, mprior_pag, df_exp_pag, Sprior_pag, df_cov_pag)\n",
    "prob_pag, pred_pag = evaluation(Xtst_pag, pi_pag, mu_pag, Sig_pag)\n",
    "\n",
    "print('\\n\\n')\n",
    "print(confusion_matrix(np.argmax(Ztst_pag, axis=1), pred_pag))\n",
    "print('\\n\\n')\n",
    "print(classification_report(np.argmax(Ztst_pag, axis=1), pred_pag))\n",
    "print('\\n\\n')\n",
    "print(precision_score(np.argmax(Ztst_pag, axis=1), pred_pag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " [[1380   26    2   22   32]\n",
      " [   6   83    0   16    5]\n",
      " [   0    0    9    0    0]\n",
      " [   0    0    0   29    4]\n",
      " [  12    0    0    1   15]]\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      1462\n",
      "           1       0.76      0.75      0.76       110\n",
      "           2       0.82      1.00      0.90         9\n",
      "           3       0.43      0.88      0.57        33\n",
      "           4       0.27      0.54      0.36        28\n",
      "\n",
      "    accuracy                           0.92      1642\n",
      "   macro avg       0.65      0.82      0.71      1642\n",
      "weighted avg       0.95      0.92      0.93      1642\n",
      "\n",
      "\n",
      "\n",
      " 0.9475484770587973\n"
     ]
    }
   ],
   "source": [
    "pi_pag_2, mu_pag_2, Sig_pag_2 = QDA_without_prior(Xapp_pag, Zapp_pag)\n",
    "prob_pag_2, pred_pag_2 = evaluation(Xtst_pag, pi_pag_2, mu_pag_2, Sig_pag_2)\n",
    "\n",
    "\n",
    "print('\\n\\n', confusion_matrix(np.argmax(Ztst_pag, axis=1), pred_pag_2))\n",
    "print('\\n\\n', classification_report(np.argmax(Ztst_pag, axis=1), pred_pag_2))\n",
    "print('\\n\\n', precision_score(np.argmax(Ztst_pag, axis=1), pred_pag_2, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satimage test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 1.0, 1: 2.0, 2: 3.0, 3: 4.0, 4: 5.0, 5: 7.0}\n",
      "\n",
      "\n",
      "\n",
      "[[442   1   6   0   3   0]\n",
      " [  0 214   0   0   3   0]\n",
      " [  5   2 361  12   2   7]\n",
      " [  0   5  53  50   3  67]\n",
      " [  4  10   0   2 189  12]\n",
      " [  1   5  17  10  15 428]]\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       452\n",
      "           1       0.90      0.99      0.94       217\n",
      "           2       0.83      0.93      0.87       389\n",
      "           3       0.68      0.28      0.40       178\n",
      "           4       0.88      0.87      0.88       217\n",
      "           5       0.83      0.90      0.86       476\n",
      "\n",
      "    accuracy                           0.87      1929\n",
      "   macro avg       0.85      0.82      0.82      1929\n",
      "weighted avg       0.86      0.87      0.86      1929\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.8640099226624413\n"
     ]
    }
   ],
   "source": [
    "Xapp_sat, Zapp_sat, Xtst_sat, Ztst_sat, mprior_sat, Sprior_sat = data_processing(\"dataset/satimage.csv\",\n",
    "                                                                                n_components_pca=30)\n",
    "\n",
    "df_exp_sat = 0.1\n",
    "df_cov_sat = 38\n",
    "\n",
    "pi_sat, mu_sat, Sig_sat = QDA(Xapp_sat, Zapp_sat, mprior_sat, df_exp_sat, Sprior_sat, df_cov_sat)\n",
    "prob_sat, pred_sat = evaluation(Xtst_sat, pi_sat, mu_sat, Sig_sat)\n",
    "\n",
    "print('\\n\\n')\n",
    "print(confusion_matrix(np.argmax(Ztst_sat, axis=1), pred_sat))\n",
    "print('\\n\\n')\n",
    "print(classification_report(np.argmax(Ztst_sat, axis=1), pred_sat))\n",
    "print('\\n\\n')\n",
    "print(precision_score(np.argmax(Ztst_sat, axis=1), pred_sat, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " [[442   1   4   1   2   2]\n",
      " [  0 212   0   0   5   0]\n",
      " [ 10   2 351  17   6   3]\n",
      " [  0   7  47  64   6  54]\n",
      " [ 15  12   1   8 165  16]\n",
      " [  1   8  22  19  15 411]]\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       452\n",
      "           1       0.88      0.98      0.92       217\n",
      "           2       0.83      0.90      0.86       389\n",
      "           3       0.59      0.36      0.45       178\n",
      "           4       0.83      0.76      0.79       217\n",
      "           5       0.85      0.86      0.85       476\n",
      "\n",
      "    accuracy                           0.85      1929\n",
      "   macro avg       0.82      0.81      0.81      1929\n",
      "weighted avg       0.84      0.85      0.84      1929\n",
      "\n",
      "\n",
      "\n",
      " 0.8425287154985674\n"
     ]
    }
   ],
   "source": [
    "pi_sat_2, mu_sat_2, Sig_sat_2 = QDA_without_prior(Xapp_sat, Zapp_sat)\n",
    "prob_sat_2, pred_sat_2 = evaluation(Xtst_sat, pi_sat_2, mu_sat_2, Sig_sat_2)\n",
    "\n",
    "\n",
    "print('\\n\\n', confusion_matrix(np.argmax(Ztst_sat, axis=1), pred_sat_2))\n",
    "print('\\n\\n', classification_report(np.argmax(Ztst_sat, axis=1), pred_sat_2))\n",
    "print('\\n\\n', precision_score(np.argmax(Ztst_sat, axis=1), pred_sat_2, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 'brickface', 1: 'cement', 2: 'foliage', 3: 'grass', 4: 'path', 5: 'sky', 6: 'window'}\n",
      "\n",
      "\n",
      "\n",
      "[[106   0   1   0   0   0   2]\n",
      " [  0 104   0   0   0   0   5]\n",
      " [  1   3  57   0   0   0  28]\n",
      " [  0   0   0  90   0   0   0]\n",
      " [  0   5   0   0  92   0   0]\n",
      " [  0   0   0   0   0  94   0]\n",
      " [  1   9   6   0   0   0  89]]\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       109\n",
      "           1       0.86      0.95      0.90       109\n",
      "           2       0.89      0.64      0.75        89\n",
      "           3       1.00      1.00      1.00        90\n",
      "           4       1.00      0.95      0.97        97\n",
      "           5       1.00      1.00      1.00        94\n",
      "           6       0.72      0.85      0.78       105\n",
      "\n",
      "    accuracy                           0.91       693\n",
      "   macro avg       0.92      0.91      0.91       693\n",
      "weighted avg       0.92      0.91      0.91       693\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.918175988629886\n"
     ]
    }
   ],
   "source": [
    "Xapp_seg, Zapp_seg, Xtst_seg, Ztst_seg, mprior_seg, Sprior_seg = data_processing(\"dataset/segment.csv\",\n",
    "                                                                                n_components_pca=18)\n",
    "\n",
    "df_exp_seg = 0.1\n",
    "df_cov_seg = 20\n",
    "\n",
    "pi_seg, mu_seg, Sig_seg = QDA(Xapp_seg, Zapp_seg, mprior_seg, df_exp_seg, Sprior_seg, df_cov_seg)\n",
    "prob_seg, pred_seg = evaluation(Xtst_seg, pi_seg, mu_seg, Sig_seg)\n",
    "\n",
    "print('\\n\\n')\n",
    "print(confusion_matrix(np.argmax(Ztst_seg, axis=1), pred_seg))\n",
    "print('\\n\\n')\n",
    "print(classification_report(np.argmax(Ztst_seg, axis=1), pred_seg))\n",
    "print('\\n\\n')\n",
    "print(precision_score(np.argmax(Ztst_seg, axis=1), pred_seg, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " [[107   0   1   0   0   0   1]\n",
      " [  0  99   2   0   0   0   8]\n",
      " [  1   3  55   2   0   0  28]\n",
      " [  0   0   0  90   0   0   0]\n",
      " [  0   3   0   0  94   0   0]\n",
      " [  0   0   0   0   0  94   0]\n",
      " [  0   8   7   1   0   0  89]]\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       109\n",
      "           1       0.88      0.91      0.89       109\n",
      "           2       0.85      0.62      0.71        89\n",
      "           3       0.97      1.00      0.98        90\n",
      "           4       1.00      0.97      0.98        97\n",
      "           5       1.00      1.00      1.00        94\n",
      "           6       0.71      0.85      0.77       105\n",
      "\n",
      "    accuracy                           0.91       693\n",
      "   macro avg       0.91      0.90      0.90       693\n",
      "weighted avg       0.91      0.91      0.91       693\n",
      "\n",
      "\n",
      "\n",
      " 0.9106168097112367\n"
     ]
    }
   ],
   "source": [
    "pi_seg_2, mu_seg_2, Sig_seg_2 = QDA_without_prior(Xapp_seg, Zapp_seg)\n",
    "prob_seg_2, pred_seg_2 = evaluation(Xtst_seg, pi_seg_2, mu_seg_2, Sig_seg_2)\n",
    "\n",
    "\n",
    "print('\\n\\n', confusion_matrix(np.argmax(Ztst_seg, axis=1), pred_seg_2))\n",
    "print('\\n\\n', classification_report(np.argmax(Ztst_seg, axis=1), pred_seg_2))\n",
    "print('\\n\\n', precision_score(np.argmax(Ztst_seg, axis=1), pred_seg_2, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9766310415063318 1;p+20 ll\n",
    "# 0.9758926103474012 10;p+20\n",
    "# 0.9671482548426473 10;p+300 \n",
    "# v reprensent the least informative -> v high -> cov lower -> more \"confident\" ????\n",
    "# high df_cov -> Sig =~~ sampling covariance matrix (in this case Sprior)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
