{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for training `QDA` :\n",
    "- takes the inputs : $X_{app}$ (training input matrix $n, p$), $z_{app}$ (binary class indicator matrix $n, K$), $m_{prior}$ (Gaussian prior expectation matrix $K, p$), $df_{exp}$ (Gaussian prior shrinkage parameter), $S_{prior}$ (covariance matrix $p, p, K$ for the inverse -Wishart prior), $df_{cov}$ (degree of freedom of the inverse-Wishart prior)\n",
    "- provides : $pi$ (vector $K, 1$ of class proportions), $mu$ (estimated expectation matrix $K, p$), $Sig$ (estimated covariance matrices $p, p, K$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QDA(Xapp, zapp, mprior, df_exp, Sprior, df_cov):\n",
    "    n, p, K =  Xapp.shape[0], Xapp.shape[1], zapp.shape[1]\n",
    "    pi = np.zeros(K)\n",
    "    mu = np.zeros((K, p))\n",
    "    B = np.zeros((p, p, n))\n",
    "    Sig = np.zeros((p, p, K))\n",
    "    \n",
    "    pi = np.mean(zapp, axis=0)\n",
    "    for j in range(K):\n",
    "        mu[j, :] = (sum(zapp[i, j] * Xapp[i, :] for i in range(n)) \n",
    "                    + df_exp * mprior[j, :]) / (sum(zapp[:, j]) + df_exp)\n",
    "        \n",
    "        for i in range(n):\n",
    "            temp = (Xapp[i, :] - mprior[j, :]).reshape((p, -1))\n",
    "            B[:, :, i] = temp @ temp.T\n",
    "        \n",
    "        Sig[:, :, j] = (sum((zapp[i, j] * B[:, :, i]) for i in range(n)) + \n",
    "                        df_exp * (mu[j, :] - mprior[j, :]) @ (mu[j, :] - mprior[j, :]).T + \n",
    "                        Sprior[:, :, j]) / (sum(zapp[:, j]) + df_cov + p + 2)\n",
    "        U, S, V = np.linalg.svd(Sig[:, :, j], full_matrices=True)\n",
    "        Sig[:, :, j] = np.diag(S)\n",
    "        print(\"min {}\".format(min(S)))\n",
    "    return pi, mu, Sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QDA_without_prior(Xapp, zapp):\n",
    "    n, p, K =  Xapp.shape[0], Xapp.shape[1], zapp.shape[1]\n",
    "    pi = np.zeros(K)\n",
    "    mu = np.zeros((K, p))\n",
    "    B = np.zeros((p, p, n))\n",
    "    Sig = np.zeros((p, p, K))\n",
    "    \n",
    "    pi = np.mean(zapp, axis=0)\n",
    "    for j in range(K):\n",
    "        mu[j, :] = sum(zapp[i, j] * Xapp[i, :] for i in range(n))\n",
    "        \n",
    "        for i in range(n):\n",
    "            temp = (Xapp[i, :] - mu[j, :]).reshape((p, -1))\n",
    "            B[:, :, i] = temp @ temp.T\n",
    "        \n",
    "        Sig[:, :, j] = sum((zapp[i, j] * B[:, :, i]) for i in range(n))\n",
    "        U, S, V = np.linalg.svd(Sig[:, :, j], full_matrices=False)\n",
    "        Sig[:, :, j] = np.diag(S)\n",
    "        print(\"min {}\".format(min(S)))\n",
    "    return pi, mu, Sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for evaluating test set `evaluation` :\n",
    "- takes the inputs : $X_{tst}$ (test input matrix $n, p$), $pi$ (vector $K, 1$ of class proportions), $mu$ (estimated expectation matrix $K, p$), $Sig$ (estimated covariance matrices $p, p, K$)\n",
    "- provides : $prob$ (matrix $n, K$ of estimated class posterior probabilities) and $pred$ (vector $n, 1$ of corresponding decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(Xtst, pi, mu, Sig):\n",
    "    n, p, K = Xtst.shape[0], Xtst.shape[1], len(pi)\n",
    "    prob = np.zeros((n, K))\n",
    "    pred = np.zeros(n)\n",
    "    \n",
    "    f = lambda x, mu, Sig: (2 * np.pi)**(-n/2) * np.linalg.det(Sig)**(-1/2) * np.exp((-1/2) * \n",
    "                                                                                     (x - mu).T\n",
    "                                                                                     @ np.linalg.inv(Sig)\n",
    "                                                                                     @ (x - mu))\n",
    "   \n",
    "    for j in range(K):\n",
    "        for i in range(n):\n",
    "            total = sum(pi[k] * f(Xtst[i, :], mu[k, :], Sig[:, :, k]) for k in range(K))\n",
    "            prob[i, j] = pi[j] * f(Xtst[i, :], mu[j, :], Sig[:, :, j]) / total\n",
    "        \n",
    "    pred = np.argmax(prob, axis=1)\n",
    "    \n",
    "    return prob, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `data_processing` function to test different dataset. The function does respectively :\n",
    "- Read the dataset by the `pandas` library and transform it to the one in form of the `numpy` library in order to facilitate our next works.\n",
    "- Apply PCA filtering process to the dataset if necessary.\n",
    "- Sort all classes of the dataset and display their enumeration\n",
    "- Separate the dataset into training and test ones by `cut_off` coefficient predefined at `0.9`\n",
    "- Calculate the prior expectation and variance based on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(file_url, n_components_pca=None, cut_off=0.9):\n",
    "    data = pd.read_csv(file_url, header=0)\n",
    "    data = data.to_numpy()\n",
    "    \n",
    "    if n_components_pca is not None:\n",
    "        data_y = data[:, -1]\n",
    "        data_X = data[:, :-1]\n",
    "        pca = PCA(n_components=n_components_pca)\n",
    "        data_X = pca.fit_transform(data_X)\n",
    "        data = np.hstack((data_X, data_y.reshape((-1,1))))\n",
    "    \n",
    "    classes = sorted(collections.Counter(list(data[:, -1])).keys())\n",
    "    classes_with_index = {}\n",
    "    \n",
    "    K = len(classes)\n",
    "    n, p = data.shape[0], data.shape[1] - 1\n",
    "    for i_class in range(K):\n",
    "        classes_with_index[i_class] = classes[i_class]\n",
    "        data[data[:, -1] == classes[i_class], -1] = i_class\n",
    "    print(\"Ours classes are enumerated as bellow : \\n\", classes_with_index)\n",
    "    \n",
    "    cut_off = int(cut_off*data.shape[0])\n",
    "    if cut_off > data.shape[0]:\n",
    "        raise IndexError(\"list index out of range\")\n",
    "    else:\n",
    "        Xapp = data[0:cut_off, :-1]\n",
    "        Xtst = data[cut_off:, :-1]\n",
    "\n",
    "        Zapp = np.zeros((cut_off, K))\n",
    "        Ztst = np.zeros((n - cut_off, K))\n",
    "\n",
    "        for i in range(cut_off):\n",
    "            Zapp[i, int(data[i, -1])] = 1\n",
    "        for i in range(cut_off, n):\n",
    "            Ztst[i - cut_off, int(data[i, -1])] = 1\n",
    "    \n",
    "    mprior = np.zeros((K, p))\n",
    "    Sprior = np.zeros((p, p, K))\n",
    "    for j in range(K):\n",
    "        temp = data[data[:, -1] == j, :-1]\n",
    "        temp = temp.astype(float)\n",
    "        mprior[j, :] = temp.mean(axis = 0)\n",
    "        Sprior[:, :, j] = np.cov(temp, rowvar=False)\n",
    "    return Xapp, Zapp, Xtst, Ztst, mprior, Sprior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `optdigits` dataset has many zero elements that make itselft correlated. That's why the result from the inital training datatset is badly evaluated. We then apply a PCA filtering process with number of principal components depending on the `cut_off` coefficient (rank of training set) in order to eliminate the correlated ones. As a result, we get much better performance. <br>\n",
    "For the choice of the shrinkage parameter $df_{exp}$ and the degree of freedom $df_{co}v$, we a priori choose $df_{exp} = 10$ and $df_{cov} = 300$ for this dataset and also the next ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
      "min 3.161863535916355e-15\n",
      "min 1.3549469712669866e-14\n",
      "min 6.5743015993287244e-15\n",
      "min 4.371824612430509e-15\n",
      "min 1.0381386596021514e-14\n",
      "min 1.0073518262080173e-14\n",
      "min 5.493874421927707e-15\n",
      "min 9.539640073915118e-15\n",
      "min 5.1302746457309e-15\n",
      "min 9.353170216388301e-15\n",
      "\n",
      "\n",
      " [[55  0  0  0  0  0  0  0  0  0]\n",
      " [58  0  0  0  0  0  0  0  0  0]\n",
      " [54  0  0  0  0  0  0  0  0  0]\n",
      " [57  0  0  0  0  0  0  0  0  0]\n",
      " [59  0  0  0  0  0  0  0  0  0]\n",
      " [56  0  0  0  0  0  0  0  0  0]\n",
      " [57  0  0  0  0  0  0  0  0  0]\n",
      " [57  0  0  0  0  0  0  0  0  0]\n",
      " [53  0  0  0  0  0  0  0  0  0]\n",
      " [56  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      1.00      0.18        55\n",
      "           1       0.00      0.00      0.00        58\n",
      "           2       0.00      0.00      0.00        54\n",
      "           3       0.00      0.00      0.00        57\n",
      "           4       0.00      0.00      0.00        59\n",
      "           5       0.00      0.00      0.00        56\n",
      "           6       0.00      0.00      0.00        57\n",
      "           7       0.00      0.00      0.00        57\n",
      "           8       0.00      0.00      0.00        53\n",
      "           9       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.10       562\n",
      "   macro avg       0.01      0.10      0.02       562\n",
      "weighted avg       0.01      0.10      0.02       562\n",
      "\n",
      "\n",
      "\n",
      " 0.009577512949430732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huydung/miniconda3/envs/aos1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/huydung/miniconda3/envs/aos1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "df_exp_opt = 10\n",
    "df_cov_opt = 300\n",
    "#cuts_off = np.array([0.9, 0.91, 0.92, 0.93, 0.94, 0.95])\n",
    "#prediction = np.zeros(4)\n",
    "\n",
    "#for i in range(len(cuts_off))\n",
    "Xapp_opt, Zapp_opt, Xtst_opt, Ztst_opt, mprior_opt, Sprior_opt = data_processing(\n",
    "                                            \"dataset/optdigits.csv\", cut_off=0.9)\n",
    "pi_opt, mu_opt, Sig_opt = QDA(Xapp_opt, Zapp_opt, mprior_opt, df_exp_opt, Sprior_opt, df_cov_opt)\n",
    "prob_opt, pred_opt = evaluation(Xtst_opt, pi_opt, mu_opt, Sig_opt)\n",
    "#prediction[i] = precision_score(np.argmax(Ztst_opt, axis=1), pred_opt, average='weighted')\n",
    "\n",
    "print('\\n\\n', confusion_matrix(np.argmax(Ztst_opt, axis=1), pred_opt))\n",
    "print('\\n\\n', classification_report(np.argmax(Ztst_opt, axis=1), pred_opt))\n",
    "print('\\n\\n', precision_score(np.argmax(Ztst_opt, axis=1), pred_opt, average='weighted'))\n",
    "\n",
    "#plt.plot(cuts_off, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 4.110401606841863e-05\n",
      "min 4.673060570472894e-05\n",
      "min 3.970506441485533e-05\n",
      "min 4.2112742503667836e-05\n",
      "min 3.9603172396172526e-05\n",
      "min 3.711041844886844e-05\n",
      "min 4.110871654263811e-05\n",
      "min 4.113779899963366e-05\n",
      "min 4.247987026190206e-05\n",
      "min 3.919020923124649e-05\n",
      "\n",
      "\n",
      " [[55  0  0  0  0  0  0  0  0  0]\n",
      " [58  0  0  0  0  0  0  0  0  0]\n",
      " [54  0  0  0  0  0  0  0  0  0]\n",
      " [57  0  0  0  0  0  0  0  0  0]\n",
      " [59  0  0  0  0  0  0  0  0  0]\n",
      " [56  0  0  0  0  0  0  0  0  0]\n",
      " [57  0  0  0  0  0  0  0  0  0]\n",
      " [57  0  0  0  0  0  0  0  0  0]\n",
      " [53  0  0  0  0  0  0  0  0  0]\n",
      " [56  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      1.00      0.18        55\n",
      "           1       0.00      0.00      0.00        58\n",
      "           2       0.00      0.00      0.00        54\n",
      "           3       0.00      0.00      0.00        57\n",
      "           4       0.00      0.00      0.00        59\n",
      "           5       0.00      0.00      0.00        56\n",
      "           6       0.00      0.00      0.00        57\n",
      "           7       0.00      0.00      0.00        57\n",
      "           8       0.00      0.00      0.00        53\n",
      "           9       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.10       562\n",
      "   macro avg       0.01      0.10      0.02       562\n",
      "weighted avg       0.01      0.10      0.02       562\n",
      "\n",
      "\n",
      "\n",
      " 0.009577512949430732\n"
     ]
    }
   ],
   "source": [
    "pi_opt_2, mu_opt_2, Sig_opt_2 = QDA_without_prior(Xapp_opt, Zapp_opt)\n",
    "prob_opt_2, pred_opt_2 = evaluation(Xtst_opt, pi_opt_2, mu_opt_2, Sig_opt_2)\n",
    "#prediction[i] = precision_score(np.argmax(Ztst_opt, axis=1), pred_opt, average='weighted')\n",
    "\n",
    "print('\\n\\n', confusion_matrix(np.argmax(Ztst_opt, axis=1), pred_opt_2))\n",
    "print('\\n\\n', classification_report(np.argmax(Ztst_opt, axis=1), pred_opt_2))\n",
    "print('\\n\\n', precision_score(np.argmax(Ztst_opt, axis=1), pred_opt_2, average='weighted'))\n",
    "\n",
    "#plt.plot(cuts_off, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 1.0, 1: 2.0, 2: 3.0, 3: 4.0, 4: 5.0}\n",
      "min 0.006666911160898614\n",
      "min 0.007048420147805417\n",
      "min 3.851911684198855e-05\n",
      "min 7.113471406531752e-05\n",
      "min 0.0024787901196926844\n",
      "\n",
      "\n",
      "\n",
      "[[450   0   0   0   0]\n",
      " [ 72   0   0   0   0]\n",
      " [  4   0   0   0   0]\n",
      " [ 17   0   0   0   0]\n",
      " [  5   0   0   0   0]]\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       450\n",
      "           1       0.00      0.00      0.00        72\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00        17\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.82       548\n",
      "   macro avg       0.16      0.20      0.18       548\n",
      "weighted avg       0.67      0.82      0.74       548\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6743166924183495\n"
     ]
    }
   ],
   "source": [
    "Xapp_pag, Zapp_pag, Xtst_pag, Ztst_pag, mprior_pag, Sprior_pag = data_processing(\"dataset/page-blocks.csv\")\n",
    "\n",
    "df_exp_pag = 10\n",
    "df_cov_pag = 300\n",
    "\n",
    "pi_pag, mu_pag, Sig_pag = QDA(Xapp_pag, Zapp_pag, mprior_pag, df_exp_pag, Sprior_pag, df_cov_pag)\n",
    "prob_pag, pred_pag = evaluation(Xtst_pag, pi_pag, mu_pag, Sig_pag)\n",
    "\n",
    "print('\\n\\n')\n",
    "print(confusion_matrix(np.argmax(Ztst_pag, axis=1), pred_pag))\n",
    "print('\\n\\n')\n",
    "print(classification_report(np.argmax(Ztst_pag, axis=1), pred_pag))\n",
    "print('\\n\\n')\n",
    "print(precision_score(np.argmax(Ztst_pag, axis=1), pred_pag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 1.0, 1: 2.0, 2: 3.0, 3: 4.0, 4: 5.0, 5: 7.0}\n",
      "min 0.006428538395930873\n",
      "min 0.0036803961289855274\n",
      "min 0.0062495768992002826\n",
      "min 0.00465272579542604\n",
      "min 0.004054574886653143\n",
      "min 0.005538926153406461\n",
      "\n",
      "\n",
      "\n",
      "[[158   0   0   0  10   0]\n",
      " [ 46  17   0   0   0   1]\n",
      " [ 35   0  97   8   0   0]\n",
      " [ 13   0  10  37   0   9]\n",
      " [ 52   0   0   0  15   2]\n",
      " [ 30   0   1  19   3  80]]\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.94      0.63       168\n",
      "           1       1.00      0.27      0.42        64\n",
      "           2       0.90      0.69      0.78       140\n",
      "           3       0.58      0.54      0.56        69\n",
      "           4       0.54      0.22      0.31        69\n",
      "           5       0.87      0.60      0.71       133\n",
      "\n",
      "    accuracy                           0.63       643\n",
      "   macro avg       0.73      0.54      0.57       643\n",
      "weighted avg       0.72      0.63      0.62       643\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.7180729070922014\n"
     ]
    }
   ],
   "source": [
    "Xapp_sat, Zapp_sat, Xtst_sat, Ztst_sat, mprior_sat, Sprior_sat = data_processing(\"dataset/satimage.csv\")\n",
    "\n",
    "df_exp_sat = 10\n",
    "df_cov_sat = 300\n",
    "\n",
    "pi_sat, mu_sat, Sig_sat = QDA(Xapp_sat, Zapp_sat, mprior_sat, df_exp_sat, Sprior_sat, df_cov_sat)\n",
    "prob_sat, pred_sat = evaluation(Xtst_sat, pi_sat, mu_sat, Sig_sat)\n",
    "\n",
    "print('\\n\\n')\n",
    "print(confusion_matrix(np.argmax(Ztst_sat, axis=1), pred_sat))\n",
    "print('\\n\\n')\n",
    "print(classification_report(np.argmax(Ztst_sat, axis=1), pred_sat))\n",
    "print('\\n\\n')\n",
    "print(precision_score(np.argmax(Ztst_sat, axis=1), pred_sat, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours classes are enumerated as bellow : \n",
      " {0: 'brickface', 1: 'cement', 2: 'foliage', 3: 'grass', 4: 'path', 5: 'sky', 6: 'window'}\n",
      "min 1.8218110108089534e-10\n",
      "min 3.5227910038145767e-10\n",
      "min 5.377091868125654e-11\n",
      "min 2.6096879675116864e-10\n",
      "min 3.187876047280485e-10\n",
      "min 8.035058541756517e-11\n",
      "min 1.1897495822012975e-10\n",
      "\n",
      "\n",
      "\n",
      "[[11 10  6  0  0  0  1]\n",
      " [ 0 31  4  0  0  0  4]\n",
      " [ 0  1 18  0  0  0  9]\n",
      " [ 0  1 16 11  0  0  1]\n",
      " [ 0 10  4  0 21  0  0]\n",
      " [ 0 30  2  0  0  6  0]\n",
      " [ 0  7  8  0  0  0 19]]\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.39      0.56        28\n",
      "           1       0.34      0.79      0.48        39\n",
      "           2       0.31      0.64      0.42        28\n",
      "           3       1.00      0.38      0.55        29\n",
      "           4       1.00      0.60      0.75        35\n",
      "           5       1.00      0.16      0.27        38\n",
      "           6       0.56      0.56      0.56        34\n",
      "\n",
      "    accuracy                           0.51       231\n",
      "   macro avg       0.74      0.50      0.51       231\n",
      "weighted avg       0.74      0.51      0.51       231\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.7407921580335373\n"
     ]
    }
   ],
   "source": [
    "Xapp_seg, Zapp_seg, Xtst_seg, Ztst_seg, mprior_seg, Sprior_seg = data_processing(\"dataset/segment.csv\",\n",
    "                                                                                n_components_pca=17)\n",
    "\n",
    "df_exp_seg = 10\n",
    "df_cov_seg = 300\n",
    "\n",
    "pi_seg, mu_seg, Sig_seg = QDA(Xapp_seg, Zapp_seg, mprior_seg, df_exp_seg, Sprior_seg, df_cov_seg)\n",
    "prob_seg, pred_seg = evaluation(Xtst_seg, pi_seg, mu_seg, Sig_seg)\n",
    "\n",
    "print('\\n\\n')\n",
    "print(confusion_matrix(np.argmax(Ztst_seg, axis=1), pred_seg))\n",
    "print('\\n\\n')\n",
    "print(classification_report(np.argmax(Ztst_seg, axis=1), pred_seg))\n",
    "print('\\n\\n')\n",
    "print(precision_score(np.argmax(Ztst_seg, axis=1), pred_seg, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9766310415063318 1;p+20 ll\n",
    "# 0.9758926103474012 10;p+20\n",
    "# 0.9671482548426473 10;p+300 \n",
    "# v reprensent the least informative -> v high -> cov lower -> more \"confident\" ????\n",
    "# high df_cov -> Sig =~~ sampling covariance matrix (in this case Sprior)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
